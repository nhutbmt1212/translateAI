# ğŸš€ Backend Connection Guide for Frontend

This guide explains how to connect your Frontend (React, Vue, etc.) to the local AI Grammar Backend.

---

> [!IMPORTANT]
> **Base URL**: `http://localhost:8000`  
> **Protocol**: HTTP  
> **CORS**: Currently set to `*` (**Allow All**) for easy development.

---

## ğŸ›°ï¸ API Endpoints

### 1. ğŸ’¬ Chat, Translate & Correct (`/chat`)
This endpoint provides the **direct English version** of your input + linguistic analysis.
- **Tá»± Ä‘á»™ng lÆ°u**: Lá»‹ch sá»­ há»™i thoáº¡i Ä‘Æ°á»£c tá»± Ä‘á»™ng lÆ°u vÃ o `chat_history.json`.
- **Ngá»¯ cáº£nh**: AI sáº½ nhá»› cÃ¡c cÃ¢u trÆ°á»›c Ä‘Ã³ Ä‘á»ƒ tráº£ lá»i tiáº¿p ná»‘i.

#### ğŸ“‚ Request Body (JSON)
```json
{
  "message": "Your text here...",
  "is_new": false
}
```
- `message`: CÃ¢u nháº­p vÃ o.
- `is_new`: 
  - `true`: XÃ³a lá»‹ch sá»­ cÅ© vÃ  báº¯t Ä‘áº§u cÃ¢u má»›i (Reset context).
  - `false`: Tiáº¿p tá»¥c há»™i thoáº¡i dá»±a trÃªn lá»‹ch sá»­ Ä‘Ã£ lÆ°u.

#### ğŸŒŠ Response
- **Type**: `text/plain` (Streaming)

---

### 2. ğŸ”„ Reset Conversation (`/reset`)
XÃ³a sáº¡ch lá»‹ch sá»­ há»™i thoáº¡i trong bá»™ nhá»› vÃ  file `chat_history.json`.

---

### 3. ğŸ›‘ Stop Generation (`/cancel`)
Dá»«ng AI ngay láº­p tá»©c khi nÃ³ Ä‘ang táº¡o pháº£n há»“i (DÃ¹ng cho nÃºt "Stop").

| Method | Endpoint |
| :--- | :--- |
| `POST` | `/cancel` |

#### âœ… Response (JSON)
```json
{ "status": "generation stopped" }
```

---

## ğŸ’» Frontend Implementation (React Example)

> [!TIP]
> Sá»­ dá»¥ng **AbortController** Ä‘á»ƒ quáº£n lÃ½ viá»‡c gá»i API vÃ  káº¿t há»£p vá»›i nÃºt Stop.

```tsx
const [isGenerating, setIsGenerating] = useState(false);

const handleChat = async (text: string) => {
  setIsGenerating(true);
  try {
    const response = await fetch('http://localhost:8000/chat', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ message: text, is_new: false }),
    });

    if (!response.body) return;
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    
    while (true) {
      const { value, done } = await reader.read();
      if (done) break;
      console.log(decoder.decode(value));
    }
  } finally {
    setIsGenerating(false);
  }
};

const stopAI = async () => {
  await fetch('http://localhost:8000/cancel', { method: 'POST' });
};
```

---

## ğŸ› ï¸ Setup & Troubleshooting

> [!WARNING]
> Äáº£m báº£o server Ä‘ang cháº¡y: `python grammar_backend.py`

---

## ğŸï¸ Cáº¤U HÃŒNH CHO HIá»†U NÄ‚NG NHANH NHáº¤T

### 1. Backend: TÄƒng Batch Size (ÄÃ£ tá»‘i Æ°u)
Backend hiá»‡n Ä‘Ã£ Ä‘Æ°á»£c Ä‘áº·t `batch_size = 15`.

### 2. Tá»‘i Æ°u GPU (4-bit quantization)
Há»‡ thá»‘ng hiá»‡n Ä‘ang sá»­ dá»¥ng **4-bit NF4 quantization**. ÄÃ¢y lÃ  má»©c cáº¥u hÃ¬nh giÃºp mÃ´ hÃ¬nh Google Gemma 2 (9B) cháº¡y mÆ°á»£t mÃ  trÃªn card 12GB mÃ  váº«n giá»¯ Ä‘Æ°á»£c Ä‘á»™ thÃ´ng minh cá»§a "GiÃ¡o sÆ°".

---

